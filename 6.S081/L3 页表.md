# L3 页表

## 虚拟内存

![image-20231127163838050](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202311271639149.png)

理解上面这张图：

1. CPU正在执行一条指令，对于任何一条带有地址的指令，其中的地址应该认为是**虚拟内存地址**（virtual address）而不是物理地址（physical address）。
2. 虚拟内存地址会被转到内存管理单元（MMU，Memory Management Unit）
3. MMU会将虚拟地址翻译成物理地址。之后这个物理地址会被用来索引物理内存，并从物理内存加载，或者向物理内存存储数据。

为了能够完成虚拟内存地址到物理内存地址的翻译，MMU会有一个表单，表单中，一边是虚拟内存地址，另一边是物理内存地址。

**SATP寄存器**：存放表单在物理内存中的地址。这样子CPU就可以告诉MMU，你要去哪里找页表。

MMU不会存页表，只负责转换。

CPU切换进程，也会切换SATP寄存器，每个进程都有一个独立的页表。写SATP寄存器是一条特权指令。

如果一个物理地址对应一个虚拟地址对应一个条目，表单就会非常巨大！

所以真正的页表，是一条表单条目对应一个page！

**RISC-V中，一个page是4KB**，也就是4096Bytes。

![image-20231127164056297](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202311281012594.png)

1. 当MMU在做地址翻译的时候，通过读取虚拟内存地址中的index可以知道物理内存中的page号（PPN，Physical Page Number），这个page号对应了物理内存中的4096个字节。之后虚拟内存地址中的offset指向了page中的4096个字节中的某一个，假设offset是12，那么page中的第12个字节被使用了。将offset加上page的起始地址，就可以得到物理内存地址。
2. offset为什么是12位？一个page是4096=2^12，对应了一个page的4096个字节。
3. 每个进程都有一个页表的话，一个页表有2^27大小，太大啦，所以就有下面的三级页表。

![image-20231127164032217](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202311281013873.png)

1. 一个page directory是4096字节，Directory中的一个条目被称为PTE（Page Table Entry）是64bits，就像寄存器的大小一样，也就是8Bytes。所以一个Directory page有512个条目。
2. SATP寄存器会指向最高一级的page directory的物理内存地址，之后我们用虚拟内存中index的高9bit索引最高一级的page directory，得到一个PPN，这个PPN指向中间级的page directory
3. 当我们在使用中间级的page directory时，我们通过虚拟内存地址中的L1部分完成索引。接下来会走到最低级的page directory，我们通过虚拟内存地址中的L0部分完成索引。在最低级的page directory中，我们可以得到对应于虚拟内存地址的物理内存地址。
4. **如果你只有一条PTE，你的PTE就只有 3*512个 而不是2^27个**！而且这里有个好处，就是如果顶层page directory的某个条目是未被使用的，就不会创建中层page directory和低层page directory。
5. 如果你把44bit的PPN和10bit的Flags相加是54bit，也就是说还有10bit未被使用，这10bit被用来作为**未来扩展**。比如说某一天你有了一个新的RISC-V处理器，它的page table可能略有不同，或许有超过44bit的PPN。

![image-20231127164115445](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202311281013290.png)

1. Valid表示是否合法
2. Readable/Writable 是否可读可写
3. Executable 是否是指令
4. User 是否可以被运行在用户空间的进程访问

## Translation Lookaside Buffer

页表缓存

三次读内存,太慢了..

当处理器第一次查找一个虚拟地址时，硬件通过3级page table得到最终的PPN，TLB会保存虚拟地址到物理地址的映射关系。这里不存offset！

切换进程，会切换页表，也会清空TLB。在RISC-V中，清空TLB的指令是sfence_vma。

## xv6的虚拟内存

![img](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202311281501452.png)

* **QEMU模拟**还包括I/O设备，如磁盘接口。QEMU将设备接口作为内存映射控制寄存器暴露给软件，这些寄存器位于**物理地址空间`0x80000000`以下。**内核可以通过读取/写入这些特殊的物理地址与设备交互；这种读取和写入与设备硬件而不是RAM通信。（**实际硬件**将RAM和设备置于不可预测的物理地址）
* 在内核启动的时候，有下面几行代码

```c
    kinit();         // physical page allocator
    kvminit();       // create kernel page table
    kvminithart();   // turn on paging
    procinit();      // process table
```

1. 创建内核的页表。此调用发生在 xv6 启用 RISC-V 上的分页之前，因此地址直接引用物理内存。

```c
void
kvminit()
{
  kernel_pagetable = (pagetable_t) kalloc();
  memset(kernel_pagetable, 0, PGSIZE);

  // uart registers
  kvmmap(UART0, UART0, PGSIZE, PTE_R | PTE_W);

  // virtio mmio disk interface
  kvmmap(VIRTIO0, VIRTIO0, PGSIZE, PTE_R | PTE_W);

  // CLINT
  kvmmap(CLINT, CLINT, 0x10000, PTE_R | PTE_W);

  // PLIC
  kvmmap(PLIC, PLIC, 0x400000, PTE_R | PTE_W);

  // map kernel text executable and read-only.
  kvmmap(KERNBASE, KERNBASE, (uint64)etext-KERNBASE, PTE_R | PTE_X);

  // map kernel data and the physical RAM we'll make use of.
  kvmmap((uint64)etext, (uint64)etext, PHYSTOP-(uint64)etext, PTE_R | PTE_W);

  // map the trampoline for trap entry/exit to
  // the highest virtual address in the kernel.
  kvmmap(TRAMPOLINE, (uint64)trampoline, PGSIZE, PTE_R | PTE_X);
}
```

```c
// add a mapping to the kernel page table.
// only used when booting.
// does not flush TLB or enable paging.
void
kvmmap(uint64 va, uint64 pa, uint64 sz, int perm)
{
  if(mappages(kernel_pagetable, va, sz, pa, perm) != 0)
    panic("kvmmap");
}
```

```c
// Switch h/w page table register to the kernel's page table,
// and enable paging.
void
kvminithart()
{
    //它将根页表页的物理地址写入寄存器satp。之后，CPU将使用内核页表转换地址。
  w_satp(MAKE_SATP(kernel_pagetable));
  sfence_vma();
}
```

在kvminit中其实是还没有分页机制的，在kvminithart中才开始有了分页机制

自此之后在内核的虚拟地址**就要经过MMU的翻译**才可以转化为物理地址了

```c
// initialize the proc table at boot time.
void
procinit(void)
{
  struct proc *p;
  
  initlock(&pid_lock, "nextpid");
  for(p = proc; p < &proc[NPROC]; p++) {
      initlock(&p->lock, "proc");

      // Allocate a page for the process's kernel stack.
      // Map it high in memory, followed by an invalid
      // guard page.
      char *pa = kalloc();
      if(pa == 0)
        panic("kalloc");
      uint64 va = KSTACK((int) (p - proc));
      kvmmap(va, (uint64)pa, PGSIZE, PTE_R | PTE_W);
      p->kstack = va;
  }
  kvminithart();
}
```

## 作业

这个Lab之前，我们需要先知道这个作业究竟要做什么（这是我做完作业之后才补充的。。）

之前的xv6，satp寄存器只有一个全局内核页表的起始地址，只有内核状态下的虚拟地址才能使用硬件MMU转换成物理地址。如果用户使用系统调用传入了一个指针（就是用户页表的虚拟地址），那么内核得用软件模拟MMU，使用用户页表将虚拟地址转化为物理地址（函数walk），效率变慢。

于是我们可以为每一个用户进程建立一张内核页表。这个内核页表首先要和全局的内核页表保持一致，并且要和该进程的用户页表合并一下，切换进程的时候，还要将它放入satp寄存器中，在内核状态下，调用该页表，使用硬件MMU自动转换虚拟地址。

### Print a page table (easy)

30min

```c
void vmprint(pagetable_t pagetable)
{
  printf("page table %p\n", pagetable);
  dfs_vmprint(pagetable, 1);
}

void dfs_vmprint(pagetable_t pagetable, int c)
{
  for (int i = 0; i < 512; i++)
  {
    pte_t pte = pagetable[i];
    if (pte & PTE_V)
    {
      for (int i = 0; i < c; i++)
      {
        printf("..");
        if (i != c - 1)
          printf(" ");
      }
      printf("%d: pte %p pa %p\n", i, pte, PTE2PA(pte));
      if ((pte & (PTE_R | PTE_W | PTE_X)) == 0)
      {
        uint64 child = PTE2PA(pte);
        dfs_vmprint((pagetable_t)child, c + 1);
      }
    }
  }
}
```

### A kernel page table per process (hard)

3hour... too difficult

修改内核来让每一个进程在内核中执行时使用它自己的内核页表的副本。每个进程的内核页表都应当**与现有的的全局内核页表完全一致**。

1. 在`struct proc`中为进程的内核页表增加一个字段

   ![image-20231129200309077](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202311292003715.png)

2. 为一个新进程生成一个内核页表的合理方案是实现一个修改版的`kvminit`，这个版本中应当创造一个新的页表而不是修改`kernel_pagetable`。你将会考虑在`allocproc`中调用这个函数。就是复制一份`kernel_pagetable`

   ```c
   //为进程分配一个内核页表
   pagetable_t proc_kvminit()
   {
     pagetable_t pagetable = (pagetable_t)kalloc();
     if (pagetable == 0) return pagetable;
     memset(pagetable, 0, PGSIZE);
   
     // uart registers
     uvmmap(pagetable, UART0, UART0, PGSIZE, PTE_R | PTE_W);
   
     // virtio mmio disk interface
     uvmmap(pagetable, VIRTIO0, VIRTIO0, PGSIZE, PTE_R | PTE_W);
   
     // CLINT
     uvmmap(pagetable, CLINT, CLINT, 0x10000, PTE_R | PTE_W);
   
     // PLIC
     uvmmap(pagetable, PLIC, PLIC, 0x400000, PTE_R | PTE_W);
   
     uvmmap(pagetable, KERNBASE, KERNBASE, (uint64)etext - KERNBASE, PTE_R | PTE_X);
   
     uvmmap(pagetable, (uint64)etext, (uint64)etext, PHYSTOP - (uint64)etext, PTE_R | PTE_W);
   
     uvmmap(pagetable, TRAMPOLINE, (uint64)trampoline, PGSIZE, PTE_R | PTE_X);
   
     return pagetable;
   }
   
   void uvmmap(pagetable_t pagetable, uint64 va, uint64 pa, uint64 sz, int perm)
   {
     if (mappages(pagetable, va, sz, pa, perm) != 0)
       panic("uvmmap");
   }
   ```

3. 确保每一个进程的内核页表都关于该进程的内核栈有一个映射。之前，每个用户进程的内核栈都映射到全局内核页表中，现在每个进程都有一张页表啦，就不需要映射到全局内核页表中了。**在进程的内核页表中进程内核栈的映射。**

   ```c
   void procinit(void)
   {
     struct proc *p;
   
     initlock(&pid_lock, "nextpid");
     for (p = proc; p < &proc[NPROC]; p++)
     {
       initlock(&p->lock, "proc");
     }
     kvminithart();
   }
   
   //proc.c  
   //static struct proc *allocproc(void)
   p->kpagetable = proc_kvminit();
   if (p->kpagetable == 0)
   {
       freeproc(p);
       release(&p->lock);
       return 0;
   }
   
   char *pa = kalloc();
   if (pa == 0)
       panic("kalloc");
   uint64 va = KSTACK((int)0);
   p->kstack = va; 
   uvmmap(p->kpagetable, va, (uint64)pa, PGSIZE, PTE_R | PTE_W);
   ```

   

4. 修改`scheduler()`来加载进程的内核页表到核心的`satp`寄存器(参阅`kvminithart`来获取启发)。不要忘记在调用完`w_satp()`后调用`sfence_vma()`，没有进程运行时`scheduler()`应当使用`kernel_pagetable`

   ```c
   if (p->state == RUNNABLE)
   {
       // Switch to chosen process.  It is the process's job
       // to release its lock and then reacquire it
       // before jumping back to us.
       p->state = RUNNING;
       c->proc = p;
       w_satp(MAKE_SATP(p->kpagetable));
       sfence_vma();
       swtch(&c->context, &p->context);
   
       kvminithart();
       // Process is done running for now.
       // It should have changed its p->state before coming back.
       c->proc = 0;
   
       found = 1;
   }
   ```

   

5. 在`freeproc`中释放一个进程的内核页表

   **这里要注意!!!** 这里当时写错了，内核栈的物理内存要释放的！其他的只用释放页表，不用释放物理内存。

   ```c
   if (p->kpagetable)
   {
       uvmunmap(p->kpagetable, p->kstack, 1, 1);
       proc_free_kernel_pagetable(p->kpagetable);
   }
   ```

   ```c
   void proc_free_kernel_pagetable(pagetable_t pagetable)
   {
     for (int i = 0; i < 512; i++)
     {
       pte_t pte = pagetable[i];
       if ((pte & PTE_V) && (pte & (PTE_R | PTE_W | PTE_X)) == 0)
       {
         // this PTE points to a lower-level page table.
         uint64 child = PTE2PA(pte);
         proc_free_kernel_pagetable((pagetable_t)child);
         pagetable[i] = 0;
       }
       else if (pte & PTE_V)
       {
         pagetable[i] = 0;
       }
     }
     kfree((void *)pagetable);
   }
   ```

6. 修改`kvmpa`这个函数，不然会报错`panic: virtio_disk_intr status`

   ```c
   uint64 kvmpa(pagetable_t pagetable,uint64 va)
   {
     uint64 off = va % PGSIZE;
     pte_t *pte;
     uint64 pa;
   
     pte = walk(pagetable, va, 0);
     if (pte == 0)
       panic("kvmpa");
     if ((*pte & PTE_V) == 0)
       panic("kvmpa");
     pa = PTE2PA(*pte);
     return pa + off;
   }
   ```

   ```c
   disk.desc[idx[0]].addr = (uint64) kvmpa(myproc()->kpagetable,(uint64) &buf0);
   ```



**其他错误记录**

`kernel/proc.h:97:19: error: field 'lock' has incomplete type`

include 要注意先后关系和嵌套关系.

一个进程新创建的时候，有一个进程的用户页表

清空用户页表的时候

```c
void
proc_freepagetable(pagetable_t pagetable, uint64 sz)
{
  uvmunmap(pagetable, TRAMPOLINE, 1, 0);
  uvmunmap(pagetable, TRAPFRAME, 1, 0);
  uvmfree(pagetable, sz);
}
```

使用uvmfree清空页表的时候，要保证叶子页表没有任何映射。

### Simplify `copyin`/`copyinstr`（hard）

1. 需要编写一个函数，将用户进程的用户页表和内核页表合并

   * 可能会出现内核页表本身就有映射，出现remap怎么办，所以这里不使用mappages，直接找到目的页表的位置，修改它的值

   ```c
   //这个函数用于把进程的用户页表复制给进程的内核页表
   //sz会传入p->sz，表示进程的整个地址空间
   //参考上面的uvmcopy函数
   //特别注意，在内核模式下，无法访问设置了PTE_U的页面
   void kvm_copy_pagetable(pagetable_t oldpt, pagetable_t newpt, uint64 sz)
   {
     pte_t * pte;
     uint64 pa, i;
     uint flags;
     
     pte_t * pte_to;
     for (i = 0; i < sz; i += PGSIZE)
     {
       if ((pte = walk(oldpt, i, 0)) == 0)
         panic("kvm_copy_pagetable: pte should exist");
       if ((*pte & PTE_V) == 0)
         panic("kvm_copy_pagetable: page not present");
       
       if ((pte_to = walk(newpt, i, 1)) == 0)
         panic("kvm_copy_pagetable: pte should exist");
   
       pa = PTE2PA(*pte);
       flags = PTE_FLAGS(*pte) & ~PTE_U;
       *pte_to = PA2PTE(pa) | flags;
     }
   }
   ```

2. 修改`fork()`, `exec()`, 和`sbrk()`.几个函数

   ![image-20231202143411259](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202312021434116.png)

   ![image-20231202143446882](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202312021434277.png)![image-20231202143551131](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202312021436317.png)

3. 不要忘记在`userinit`的内核页表中包含第一个进程的用户页表

   ```c
     // allocate one user page and copy init's instructions
     // and data into it.
     uvminit(p->pagetable, initcode, sizeof(initcode));
     p->sz = PGSIZE;
   
     kvm_copy_pagetable(p->pagetable, p->kpagetable, p->sz);
   ```



就是虚拟机性能有点废，要跑好久。。

![image-20231202144718959](C:/Users/z1382/AppData/Roaming/Typora/typora-user-images/image-20231202144718959.png)



