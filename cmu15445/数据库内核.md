# 数据库内核

## SQL语法

### SQL特点

- 综合统一 (DDL,DML,DCL于一体)
  - 数据操纵语言 **DML**： select, insert, update, delete (M: manipulation)
  - 数据定义语言 **DDL**： create, drop, alter (D: definition)
  - 数据控制语言 DCL： grant, revoke (C: control)
- 高度非过程化
- 面向集合的操作方式
- 同一种语法结构提供两种使用方式 (自含式、嵌入式)
- 语言简洁，易学易用 (动词少)

助记：统过两简集(捅过两碱基)

### 单表查询（各子句用法）

```sql
SELECT DISTINCT/ALL 目标列表达式
FROM 表名/视图名
WHERE 条件表达式
GROUP BY 列名 HAVING 条件表达式
ORDER BY 列名 次序;
```

投影运算：查询列、消除重复元组、别名、计算列

* 查询列 `select x, y from TAB;`

* 消除重复元组 `select DISTINCT x from TAB;`

* 别名 `select x x1, y y1 from TAB t;`

* 计算列 （把查询的结果进行聚集操作（AGGREGATES））

  ```sql
  select count(*) from SC;
  select count(distinct Sname) from SC;
  select avg(Grade) from SC;
  select sum(distinct Grade) from SC;
  select max(distinct Sage) from SC;
  select round(avg(rating), 2) .. 
  ```
  
  

选择运算：比较运算、范围查询、集合查询、空值查询、字符匹配、逻辑查询

* 比较运算 `select Sname from SC where Sdept = 'sc';`

* 范围查询 

  ```sql
  select name, sex
  from TAB
  where age BETWEEN 20 AND 30;
  ```

* 集合查询

  ```sql
  select Sname
  from SC
  where Sdept IN ('CS', 'MA', 'IS');
  
  --where Sdept NOT IN ('CS', 'MA');
  ```

* 空值查询

  ```sql
  select Sname 
  from SC
  where Grade IS NULL;
  
  --where Grade IS NOT NULL;
  ```

* 字符匹配

  `%`多个字符

  `_`一个字符

  ```sql
  --a%b 以a开头,以b结尾的任意长度字符串
  select Sname
  from Student
  where Sname NOT LIKE '刘%';
  ```

* 逻辑查询

排序运算、聚合查询

* 排序运算

  ```sql
  select Sno, Grade
  from SC
  where Cno = '3'
  order by grade DESC;
  ```

* 聚合查询 （like a where clause for a group by) 聚集完再筛选

  ```sql
  select Sno, Grade
  from SC
  group by Sno
  having avg(Grade) >= 90;
  ```


分页查询

```sql
select sid, name from student
where login like '刘%'
LIMIT 20 OFFSET 10
```



### 连接查询

等值/非等值连接

```sql
select Student.Sno, Sname
from Student, SC
where Student.sno = SC.sno and SC.Cno = '2' and SC.Grade > 90;
```

```sql
select name, round(avg(rating), 2) as avg_rating
from Batman_actor 
INNER JOIN crew
on crew.person_id = Batman_actor.person_id
```

使用`INNER JOIN`跟上面结果一样

### 嵌套子查询

IN/NOT IN、使用比较运算符（=ANY、！ALL与IN、NOT IN等价）

```sql
select Sno, Sname, Sdept
from student
where Sdept in
	(select Sdept
     from Student
     where Sname = 'Lily');
```

```sql
select Sno, Cno
from SC x
where Grade >= 
	(select avg(Grade)
     from SC y
     where y.Sno = x.Sno);
```

```sql
select * from course
where not exists(
	select * from enrolled
    where course.cid = enrolled.cid
);
```

 ### common table expressions

临时的视图

```sql
with cteName (maxID) AS (
	select MAX(sid) from enrolled
)
select name from student, cetName
where student.sid = cteName.maxID
```

### window function

```sql
SELECT * FROM (
	SELECT *, RANK() OVER (PARTITION BY cid
		ORDER BY grade ASC) AS rank
	FROM enrolled) AS ranking
WHERE ranking.rank = 2;
```

`函数名 over (partition by xxx order by xxx)`

* 排名窗口函数

  * `ROW_NUMBER()`：为分区中每行数据分配一个序列号 1,2,3,4,5
  * `RANK()`：名次相同，发生跳跃 1,2,2,2,5
  * `DENSE_RANK()`：名次相同不发生跳跃 1,2,2,2,3

* 聚合窗口函数

  ![image-20240202163615418](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202402021636933.png)

### 处理查询结果

#### 字符拼接

```sql
select premiered, primary_title || ' (' || original_title || ')'
```

#### 判断null

判断第一个表达式是否为null，如果是，则返回第二个值

```sql
select primary_title, ifnull(ended, 2023) - premiered as time
```

#### 拼接成一行输出

```sql
select
  group_concat(character)
from
  tb2;
```

## 存储引擎

![image-20240326172348398](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202403261723710.png)

![image-20240326172603775](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202403261726484.png)

**基于磁盘的DBMS**

* 数据库存在磁盘上
* 数据库文件被划分为页，文件的第一页是`directory page`，指明每一页存在哪个物理地址
* 有个`Buffer Pool`管理数据在磁盘和内存之间流动
* `Execution Engine`执行语句，告诉缓存池需要哪个页面，缓存池将页面从磁盘调入内存，并将页面在内存中的位置的**指针**还给执行器

**OS vs DBMS**

The DBMS (almost) always wants to control things itself and can do a better job at it since it knows more about the **data being accessed** and the **queries being processed**.

→ Flushing dirty pages to disk in the correct order. （脏页什么时候存回去？）

→ Specialized prefetching. （预先取什么数据？）

→ Buffer replacement policy.  （缓存替换策略）

→ Thread/process scheduling. （多线程问题）

### File Storage

* 以文件的形式存储
* 操作系统看这些文件就是一堆0和1，只有DBMS才能解析这些文件
* `storage manager`：管理、维护数据库文件

#### Datebase Pages

* types：tuples, meta-data, indexed, log records
* 一些数据库会固定页的类型
* 个别数据库不会。`self-contained（自解释）`，读入这个页前，不知道这个页的类型
* There are three concepts of pages in DBMS: 
  1. Hardware page (usually 4 KB). 
  2. OS page (4 KB). 
  3. Database page (1-16 KB).
* The storage device guarantees **an atomic write** of the size of the hardware page.（最小原子操作数据块）。你往数据库写4KB数据（假设当前的hardware page 就是4KB），发生错误，这4KB数据一定没写入磁盘。但是你往数据库写16KB数据，发生错误，可能一个4KB失败，其他三个4KB都成功了。

#### Database Heap

**A heap file** is an unordered collection of pages where tuples are **stored in random order.**

* **Linked List**

  ![image-20240326183445002](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202403261834894.png)

* **Page Directory**

  ![image-20240326183535755](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202403261835281.png)

### Page Layout

一个页里面有啥？？

![image-20240326183656631](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202403261836673.png)

**数据在页里面怎么存？**有下面两种方式：

#### Tuple-oriented

![image-20240326183907887](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202403261839304.png)

* 最常用的一种方式！
* slot array记录着每一个元组的起点位置
* The page is considered **full** when the slot array and the tuple data meet.

#### Log-structured

![image-20240326184149165](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202403261852220.png)

* 写很快，但读很慢、压缩很麻烦

  ![image-20240326184339572](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202403261844790.png)

* 加个索引，比如给3号tuple有关的log加个索引，连起来，读的时候比较简单。

### Tuple Layout

![image-20240326184701967](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202403261847038.png)

* 有个判断元组是否为空的bit
* 元组不需要存meta-data
* Unique Identifier: page id + (offset or slot).
* Denormalized Tuple Data: 如果两个表相关联，提前将两个表合并成一个表，读的速度会变快（因为你只用加载一张表），但是更新的速度会变慢（因为tuple变大了）

### Date Representation

* Integers：C/C++ Representation （ IEEE-754 standard）

   INTEGER, BIGINT, SMALLINT, TINYINT.

* Variable Precision Numbers：就是不需要特别精确的浮点数，使用IEEE-754 standard

  FLOAT, REAL

* Fixed-Point Precision Numbers：需要特别精确的浮点数，将浮点数存成字符串。

  ![image-20240326185903397](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202403261859106.png)

  NUMERIC, DECIMAL.

* Large Values：数据很长，比如存一篇小说？？使用溢出页

  ![image-20240326190046855](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202403261900886.png)

* External Value Storage：外部文件，但是缺点在于，DBMS无法保证文件的安全。需要外部系统自己保证。

  ![image-20240326190226279](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202403261902512.png)

* Dates and Times：some unit time (micro/milli)seconds since the unix epoch. （感觉是时间戳？）

**tuple一定是按行存储嘛？**不是的，也可以按列存储，具体按行还是按列，根据worloads决定。

### Workloads

* **OLTP: Online Transaction Processing**

  进行一些简单的，规模小的，要求速度快的操作。

  ```sql
  SELECT P.*, R.*
  FROM pages AS P
  INNER JOIN revisions AS R
  ON P.latest = R.revID
  WHERE P.pageID = ?
  ```

  例如：用户与用户之间进行微信支付

* **OLAP: Online Analytical Processing**

  复杂的，规模大的分析操作。涉及多张表，又要遍历表。

  ```sql
  SELECT COUNT(U.lastLogin),
  EXTRACT(month FROM
  U.lastLogin) AS month
  FROM useracct AS U
  WHERE U.hostname LIKE '%.gov'
  GROUP BY
  EXTRACT(month FROM U.lastLogin)
  ```

  例如：微信要统计一下这个用使用微信支付的交易量

* **HTAP: Hybrid Transaction + Analytical Processing**

  两者的融合。既支持小规模操作，又支持大规模分析。

![image-20240326191924733](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202403261919929.png)

![image-20240326192252930](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202403261922137.png)

* 用户交易在Silos上进行，异步就是不是交易的同时分析，而是一段时间，将交易数据，拿出来大数据工程师进行分析。分析的结果可以存回小数据库。比如用户可以在微信上看到本月账单等数据（就是分析汇总后的结果）

### Storage Models

#### N-Ary Storage Model (NSM)

按行存储

![image-20240326192702996](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202403261927003.png)

* 优点：插入、更新、删除数据很快。查询整个tuple时很快。
* 缺点：扫描某一列的时候很慢。会产生一些无用数据。比如你只需要求出全班同学的平均分，那么同学的名字这一列就是无用数据。

#### Decomposition Storage Model (DSM)

按列存储

![image-20240326193004597](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202403261930726.png)

* 优点：按列进行分析的速度变快，有利于数据压缩
* 缺点：Slow for point queries, inserts, updates, and deletes because of tuple splitting/stitching. （point queries 点查询，就是查询某个tuple）

![image-20240326193536309](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202403261935431.png)

## 缓存池

![image-20240327102101695](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202403271021010.png)

* Each array entry is called a **frame**

* `page table`：page ID  <-->  a copy of the page **in buffer pool frames**

  `page firectory`：page ID  <-->  page locations **in database files**

* 页表对于每个页还有额外的元数据：

  * dirty-flag ：表示这个页被修改过，必须要写回磁盘
  * pin/reference Counter ：记录正在访问该页面的进程数，当进程数大于0，就不能把这个页面从内存删掉。

* locks：逻辑上的，抽象的锁

  latches：具体的，底层的锁，也叫mutex

### Buffer Pool Optimizations

优化缓存池性能的策略

#### Multiple Buffer Pools

多个缓存池。

设置多个缓存池，比如每个数据库一个缓存池、每种页类型一个缓存池（tuple、meta-data、log...)。也可以使用哈希，对每个page id进行哈希，分配到不同的缓存池。

#### Pre-Fetching

![image-20240327104012186](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202403271040452.png)

预取策略。

* 顺序扫描：如上图，要遍历整页，读取了0和1，预先知道一定要读取2和3，将2和3提前取出来，放进缓存池。

![image-20240327104340486](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202403271043617.png)

* 索引扫描：预先知道的范围在100-250，预先知道了一定需要3和5，将其提前加载到缓存池中

#### Scan Sharing

多个sql语句读同一张表，同步扫描。

![image-20240327104638520](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202403271046455.png)

* Q1正在遍历，Q1遍历到page3时，来了一个Q2
* Q2可以跟着Q1一起扫描
* Q1扫描完了，Q2再自己将page0-2扫描一遍

#### Buffer Pool Bypass

将一些不会反复使用的页面，不放缓存池，读了就丢。

对于读大量的页面，有优化作用。

对于暂时性的数据也有用，比如joins

### 替换策略

#### LRU

使用一个timestamp记录最近一次使用这个页面的时间

遍历整个缓存池，找到一个oldest timestamp，删掉

#### CLOCK

![image-20240327105621449](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202403271056587.png)

* 每个页有一个reference bit，当它被用了，ref=1
* 时针转圈圈，转到当前页，ref=1，就将其设为0；ref=0，就说明转了一圈，都没人用过你，就把你删掉。

问题：

* 当顺序扫描时，LRU算法没有任何优势，每次加入缓存池的页面，在未来都不会再被使用，怎么优化？

#### LRU-K

参考

[LRU-K]: https://zhuanlan.zhihu.com/p/622224538

永远最先驱逐访问次数小于K次的Page。维护两个链表，一个叫做history list，另一个叫buffer list。新加入的page总会先进入history list，当访问次数等于指定的次数K次时，就会从history list删除，并移动到buffer list的尾部（**这里还是假设尾部的page是最新使用的，头部page是最近最久未使用的**）。

![image-20240327143702503](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202403271437721.png)

两个list使用的淘汰算法可能是不一样的。两个list的size之和就是buffer pool的size。

#### localization

根据每个查询选择要删除的页面，跟自己有关的驱逐，跟别人有关的不驱逐，减少每个查询对缓存池的污染。

#### priority hints

事务直接告诉缓存池，这个页面是否重要，重要就一直不要驱逐。

#### dirty pages

`background writing`：DBMS定期地，集中地，悄悄的在内部把dirty page写回disk，DBMS可以选择将dirty page从缓存池中删掉，或者只是重置dirty flag。

如果关机，脏页未持久化怎么办？设置一个log record，log record要记录在disk上。

## Hash Table

空间复杂度 O(1)

时间复杂度 理想情况下O(1)，最差O(n)

* Hash Function：a large key space <--> a small domain，要平衡好速度和碰撞率。
* Hashing Scheme：如何处理碰撞

### Static Hashing Schemes

哈希表大小固定

* **Linear Probe Hashing**

  也叫开放地址哈希。当碰撞发生，填充下一个位置。

  当key不唯一时：

  ![image-20240330182741255](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202405131820383.png)

* **Robin Hood Hashing**

  平均一下，不要让贫富差距太大。

  ![image-20240330182939726](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202405131820875.png)

  * key后面加多一位，记录距离其本来应该存在的位置的距离。
  
* 上图，发现E会变成 `E|val[3]`，3太大了，但是它可以跟D换个位置
	
		`D|val[2]` 和`E|val[2]`，两者平均一下

* **Cuckoo Hashing**

  ![image-20240330183648410](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202405131821027.png)

  * 有两个哈希函数
  * 当插入C时，发现，使用两个哈希函数算出来的位置都被占了。
  * 我先把B的位置占了，让B重新找位置
  * B再把A的位置占了，让A重新找位置
  * A就得到了一个新位置。

### Dynamic Hashing Schemes

* **Chained Hashing**

  拉链哈希，就是一个节点，后面串了一串链表

  问题就是，可能链表太长了，有的优化就是，一个节点后面带着一棵红黑树

  ![image-20240330184121493](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202405131821062.png)

* **Extendible Hashing**

  ![image-20240330185545508](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202405131821514.png)

  * 当global = 2时，根据二进制的前两位分进不同的bucket里

  * 当一个bucket满了，将global置为3，新添一个bucket

    把10分成101和100

    ![image-20240330185801964](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202405131821127.png)

  * 然后重新分配原本bucket中的key

* **Linear Hashing**

  ![image-20240330185909636](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202405131821042.png)

  * 当n=4，所有key都模4，放入bucket中

  * 当某个bucket满了，连多一个bucket，并移动Split Pointer

  * 从这以后，指针上面的数模n；指针下面的数模2n

    比如上图的20，模n余0,0在指针上面，再模一次8，余4；所有20存在第4个bucket中。

  * 来个9,9%4=1，1在指针下面，存进第1个bucket

## B+Tree

### 表索引

* 索引是帮助MySQL高效获取数据的**排好序**的**数据结构**
* 表索引就是我们在表中属性的子集的一个**副本**
* 哈希表不能完成范围查询
* 有点像**书本的目录**
* 当我们对表进行更新时，也必须更新索引

![image-20240330190800893](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202405131821040.png)

### B+Tree

![image-20240330191331455](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202405131821657.png)

* 中间层的结点value保存的是指针，key判断向左走还是向右走

  叶子层的结点value保存的是数据，key判断是否是你要的东西

![image-20240330191521749](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202405131821588.png)

* key和value通常是分开保存的，因为我们并不需要用到value，拆分后，可以更高效地在key之间跳转。

* B树和B+树的区别：

  原始 B-Tree 中**所有的结点存储了value。**而B+Tree 仅将值存储在叶节点中，非叶子结点仅指导搜索过程。在B-Tree中**不会有任何重复的key**，我可以保证我的树中每个key仅出现一次。而在B+Tree中，非叶子结点存储的是路标，会有重复的key。B树的非叶子结点总是乱动，导致多线程更新的时候，代价昂贵

* node大小如何设定？

  根据workload，AP操作，结点比较大；TP操作，结点比较小。

* 如何处理可变长的key？

  * B+Tree结点不存放key本身，而是存放指向key的指针。
  * 不管你key是多大，我的node是一定比你大的，多余的空间我放null和0好了，让所有数据都完美对齐。
  * 当结点长度可变化，去适应key的长度不一。这是一种很糟糕的办法

* 如何处理非唯一键？

  * 类似 **chained hashing**，每个 key 只出现一次，但同时维护另一个链表，存储 key 对应的多个 values
  * 存储多个 key-value

* 在结点进行搜索的方式：

  * 线性扫描：很常用，因为加载page到memory的时间比较长，遍历page的时间反而显得很短很短。
  * 二分查找

### B+Tree优化

* 前缀压缩

  ![image-20240330194840169](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202405131821814.png)

* Deduplication

  ![image-20240330194954288](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202405131822344.png)

* Bulk Insert：建 B+ Tree 的最快方式是先将 keys 排好序后，再从下往上建树


### 索引并发控制

* Locks：一般是指行锁、范围锁、表锁这些。用来做**事务之间**的并发控制。是更为上层的抽象锁。
* Latches：如 `mutex`、`rwlock`、`semaphore`、`spinlockde等，`来做**线程之间**的并发控制。是更为底层的锁。锁具体的数据结构

#### latch implementations

* Blocking OS Mutex

  Example：std::mutex

  用户空间设置一把锁，多线程抢这个锁，没抢到的就被阻塞。（涉及到用户态和内核态的转换）

  优点：简单

  缺点：因为操作系统的调度，开销大，并且支持的线程数量有限（较少）

* Test-and-Set Spin Latch

  自旋锁

  ```c++
  std::atomic_flag latch;
  ⋮
  while (latch.test_and_set(…)) {
  // Retry? Yield? Abort?
  }
  ```

  一直占着cpu判断自己的机会是不是到了

  Java中的同步互斥是先采用自旋锁，在等待规定时间后这个锁仍然没有被解开就使第二个线程陷入内核态休眠。

* Reader Writer Latches

  1. 第1个进程进来，加了一把读锁。
  2. 第2个进程过来，又加了一把读锁，因为读锁是兼容的所以可以加两把。
  3. 右边第3个进程过来想要加写锁，但因为不兼容，只能等待。
  4. 第4个进程过来了，想读，但是不可以，因为会对第3个写锁不公平，会使得第3个锁会被陷入饥饿状态。

#### Hash Table Latching

哈希表加锁很方便，因为**加锁的方向都是一致**的，所有人都是往同一方向走。如果哈希表需要扩容就给全局加一个锁。

哈希表加锁按照粒度分为 page latches 和 slot latches 。

* page latches

  <img src="https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202404092017618.png" alt="image-20240409201652967" style="zoom:50%;" />

  一个线程操作时，就给这一段加锁（也可以称为页？桶

* slot latches

  <img src="https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202405131822258.png" alt="image-20240409201850883" style="zoom:50%;" />

  一个槽一个槽加锁，就是锁有点多

* Go语言中的map处理方式是存在两个hash表，读写分离，其中一个主的哈希表是只读表，还有一个是写表，然后定期挪数据。好处是**读的时候是无锁的。**

#### compare-and-swap

CPU如果提供一些用来构建锁的atomic指令，譬如x86的XCHG或CMPXCHG（加上LOCK prefix），能够完成atomic的[compare-and-swap](https://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Compare-and-swap) （CAS），用这样的硬件指令就能实现[spin lock](https://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Spinlock)。

![image-20240409202140035](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202405131822885.png)

* 我要将M地址的数改成30
* 先判断M地址的数是不是20，是的话再改，不是的话，就自旋，不停判断

#### B+Tree Latches

Crabbing Protocol（蟹行协议）

1. 获取父节点的锁
2. 获取子节点的锁
3. 判断当前节点是否安全，安全则释放父节点的锁
   * insert操作：当前节点还有空位就还是安全的（不会split）
   * remove操作：当前节点半满则是安全的（不会merge）
   * getValue操作：一直安全

每次都会锁住根节点，而事实是，大部分操作都不会影响根节点。引入乐观锁：从根节点开始，一直上读锁；如果发现出现merge或split操作，就把读锁解了，从根节点开始一路上写锁，重来一遍。

**悲观锁**：总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会阻塞直到它拿到锁（**共享资源每次只给一个线程使用，其它线程阻塞，用完后再把资源转让给其它线程**）。

**乐观锁**：总是假设最好的情况，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据

B+Tree支持叶子结点的扫描，但如果是双向扫描，可能会出现死锁的现象。解决办法，像MySQL只支持单向扫描，就不会出现死锁的现象。

## 排序和聚集

本课程中的数据库系统是面向硬盘的，即假设硬盘存储巨量数据，**不能指望这些面向硬盘的数据库系统所有的结果都保存在内存中**。

**为什么要排序？**

1. 因为数据库系统查询的返回值的顺序是不定的。如果不加 order by 就不要指望他有任何顺序，这是完全无序的。所以需要排序。

2. 不仅仅是 order by 需要排序，像 DISTINCE 、GROUP BY 指令也需要有排序这个需求。
   * DISTINCE 指令的主要工作是先排序，然后去重。
   * GROUP BY 是分组聚合指令，需要把相同的类型聚集在一起，更需要用到排序操作。

**外部归并排序**

* Early Materialization（早物化）：Key和tuple data一起排序
* Late Materialization（晚物化）：Key带上一个record Id排序

![image-20240409205103651](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202404092051762.png)

**二路归并**

![image-20240409205435622](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202404092054798.png)

  ![image-20240409205514152](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202404092055096.png)

  ![image-20240409212652925](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202404092126627.png)

![image-20240409212950387](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202404092129818.png)

1. 构造初始“归并段”，16页，输入缓冲区大小为2，两页两页内部有序（0-1页内部是有序的），最终形成了8个归并段
2. 后面就是进行归并排序，当某个输入缓冲区满了，就换一个新的上去。

在MySQL中一个页才16kb，现在服务器的内存远不止这么少。改进优化：

* **预读取**，上一个page读取在内存中做排序的过程中，可以先预读取下一页

* 可以做N路归并排序，N代表页数、B代表缓存池。缓存池的大小越大，排序的轮数越少。

  举个例子：N=108, B=5

  * 构造初始归并段：ceil(108/5)=22，（0-4页页内有序）一共有22个归并段
  * 第一次归并：ceil(22/4) = 6，拿出一个缓冲区作为输出缓冲区。变成6个归并段
  * 第二次归并：ceil(6/4)=2，变成两个归并段
  * 第三次归并：合二为一

**聚集**

**存储引擎指的不是形容数据库的，存储引擎是形容数据表的。**

聚集索引：叶子节点包含了完整的数据记录。

非聚集索引：索引文件和数据文件是分离的。

* 排序

  <img src="https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202405131822104.png" alt="image-20240409213847235" style="zoom:67%;" />

DISTINCE 的目的仅仅是想去重，这时候如果我们非要进行排序就浪费了。

* 哈希聚集

  先给我们要聚集的字段以它为key做一个哈希表。给他们映射到磁盘上。其**核心思想是利用哈希碰撞**。

  把碰撞的key放在同一个桶里。接下来需要 REHASH。因为相同key的因为碰撞放在了同一个桶中，但是还可能有的key就是因为本身hash函数导致的碰撞被放在了同一个桶中。

  REHASH（再次hash）：将桶里的key进行第2次哈希，因为相同的key得到的hash一定也是相同的，所以可以把key本身不同导致的因为hash缺陷而误放在一个桶的key给筛选出来，剩下的在一个桶里的一定就是key相同的key了。

* 有些聚集是为了计算，可以记录中间结果。

  ![image-20240409214311384](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202404092143798.png)

**对NULL值的处理**

- count(*)：不忽略NULL值，有几行算几行；
- count(num)：如果字段值为NULL，该行忽略不统计。
- SUM函数，会忽略NULL值，对非NULL值求和。
- max, min 会忽略NULL值
- 排序：升序NULL最先输出



## 连表算法

笛卡尔积会产生巨大的中间结果。

使用I/O Cost 衡量连表算法的好坏

<img src="https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202404161132349.png" alt="image-20240416113234123" style="zoom:50%;" />

### Nested Loop Join

**嵌套循环连接**

所有数据库都支持。

* **Simple / Stupid**

  ![image-20240416113134080](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202404161131755.png)

  就是两个for循环，遍历内表和外表

  * R表为外表的话：

    cost = M + (m * N)

  * 尽量去小表当外表（就是一页中tuple数少的）

  **缺点**：缓存池没用

* **Block**

  ![image-20240416113530284](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202404161135438.png)

  外表取一页，内表取一页，for循环两页

  * R表为外表的话

    cost = M + (M * N)

  **如果缓存池很大**

  假设缓存池有B页

  ![image-20240416113923256](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202404161139102.png)

  * 1页作为输出缓冲区，1页存S表，B-2页存R表

  * cost = M + (ceil(M / (B - 2)) * N)

  * 当B > M + 2，整个外表都能塞进缓存池

    cost = M + N

  **缺点**：总是需要循环扫描内表

* **Index**

  给内表加个索引，假设通过索引遍历B+Tree需要C次I/O操作

  ![image-20240416114331948](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202404161143647.png)

### Sort-Merge Join

* 先给两个表排序
* 再使用归并

![image-20240416114618349](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202404161146849.png)

![image-20240416114715269](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202404161147365.png)

* 如果两列全是一样的值，就退化成Stupid Nested Loop Join
* cost 就是排序的时间 + 归并的时间

<img src="https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202405131822310.png" alt="image-20240416114832900" style="zoom:67%;" />

* 这种算法在两种情况下特别好用：
  * 本来两张表就有序（或者一张表有序）
  * 输出结果要求有序

### Hash Join

![image-20240416115048648](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202404161150648.png)

* 存在一种情况就是，S表在R表中没有匹配的（匹配失败）
* 建一个Bloom Filter（布隆过滤器），现在布隆过滤器判断是否存在匹配，存在的话，再去哈希表匹配。

**什么是布隆过滤器？**

<img src="https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202404161155536.png" alt="image-20240416115508563" style="zoom:67%;" />

* 多个哈希函数，对空间的利用率变大
* 假设现在拿`baidu.com`来查询，经过两个哈希函数，输出分别为4和5，4对应的BitSet为1,5对应的为0，就说明不匹配。
* **布隆过滤器只适合有内存开销限制、并且允许出现错误率的情况**

当两个hash table都无法放入内存时

**Grace Hash Join**

![image-20240416120032303](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202404161200363.png)

* R表和S表能连接的表一定是在编号相同的桶里
* cost = 3(M + N)
  * 建哈希表，因为整张哈希表不能放在内存中，所以建好的哈希表要存回硬盘（这里假设建好的哈希表也是M页）这里的cost = 2(M + N)
  * 进行哈希匹配 (M + N)

如果这个桶也无法放入内存呢？

**Recursive Partitioning**

![image-20240416120250861](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202404161202086.png)

* 不断递归分桶，直到桶能放入内存中

### 总结

![image-20240416120630926](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202404161206118.png)

## 查询执行

### 执行模型

A DBMS's processing model defines **how the system executes a query plan**.

#### Iterator Model

**火山模型**

![image-20240416131023833](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202404161310787.png)

* 顶部函数不断的调用叶子函数，等待叶子函数有返回值了上面的顶部函数才能继续下去，否则一直处于阻塞状态。

#### Materialization Model

**物化模型**

![image-20240416131156130](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202404161311323.png)

* 一次吐全部数据
* 使用与OLTP，点查询比较多，返回的数组比较小

#### Vectorized/Batch Model

向量化模型

中和了火山模型和物化模型

![image-20240416131326667](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202404161313611.png)

对火山模型做改进，Next()方法不再返回一条数据，而是返回数条数据。

* 这种向量模型对OLAP型数据库友好。
* Intel最新处理器含有AVX指令集，它有一条指令（SIMD指令）可以实现在一个时钟周期内处理多条数据。例如元组中4个数值都需要与数字2做对比，那么AVX指令集可以一次性处理这个元组得到大于数字2的元素。**如果数据库使用向量化模型就可以完美利用指令集的这一特性。**

### 访问方法

最下面的算子怎么获取表中的数据？

#### Sequential Scan

![image-20240416131620762](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202404161316864.png)

遍历每张表，遍历每个tuple

**优化的方法**：

* 预取：在上张表进行操作的时候，提前读取下一张表

* Buffer Pool Bypass：不使用缓存池

* Parallelization：多个并发的线程或者进程来执行顺序扫描

* Zone Maps：给每个page做一个统计信息

  <img src="https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202404161319405.png" alt="image-20240416131949304" style="zoom:67%;" />

  问题：占用空间；这统计信息存哪？我现在要解决的是这个page要不要读到内存中的问题，如果把统计信息存在page中，那不就白忙活了；如果原始信息变了，统计信息是不是要改？会不会更麻烦。

* Heap Clustering

* Late Materialization：向上返回行id，最后一步再去取数据

  <img src="https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202404161320618.png" alt="image-20240416132057996" style="zoom:67%;" />

#### Index Scan

索引扫描

#### Multi-Index / "Bitmap" Scan

多索引扫描

![image-20240416132311693](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202404161323994.png)

### 修改查询

修改查询涉及到 insert、update、delete。与select不同，他们是对数据库做修改的。

在insert一条数据之前，不能无脑的就插入了。还有检查约束（唯一性等），如果有索引的话还要更新索引，如果page由统计信息，还要更新统计信息。

* 与晚物化一样，例如删除：**要求子算子一个个把id吐出来就行了，然后我去删除记录。**
* 但是update算子要记录这次update了什么数据。

<img src="https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202404161332852.png" alt="image-20240416133253202" style="zoom: 50%;" />

* Andy的数据：删除->更新->重新插入，会出现在

  <img src="https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202404161334979.png" alt="image-20240416133427838" style="zoom:50%;" />

  指针往后挪的时候，由再一次访问了这一条数据

  重复访问同一元组，这一问题叫做**Halloween Problem**

### 表达式计算

DBMS将WHERE语句表示成expression tree

![image-20240416133852405](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202404161338566.png)

但是可能会出现常量重复计算的问题

例如你书写一个`where 1 = 1`

![image-20240416134014696](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202404161340738.png)

这里补充一个Java中的JIT技术。JIT可以把Java字节码中不断重复的代码转换为二进制，这样可以提高效率。

### 并行执行

为什么要考虑并行执行？

* 提升性能：提升吞吐量，降低延迟
* 增强响应性和可用性
* 降低总拥有成本TCO：什么是TCO？简单的来说就是衡量一台机器使用寿命、价格、处理总数据量、电费这些成本后得出来的参数。

并行数据库和分布式数据库：

* 并行数据库：资源都在一起。线程之间的通信简单可靠。不同资源之间连接十分迅速。
* 分布式数据库：可能物理意义上相隔很远，不同结点之间的沟通非常困难而且没有可靠性保障，结点之间交流可能失败，代价也比较高。

下面讲的都是并行数据库。

一个应用程序可能会发送一个非常大的请求或者多个不同的请求，数据库系统将请求处理分散到多个工作者（worker）上。

#### 处理模型

* 每个工作者对应一个进程。当应用程序想要发送请求给数据库系统时，调度器会收到这个请求并让一个工作进程来处理这个(fork一个新的进程)，然后工作进程直接和应用程序进行交互。维护一个**共享内存**进行进程之间的通信。

  ![image-20240417165229386](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202404171652671.png)

* 进程池。不是每次收到请求都去专门创建对应的进程来处理，而是创建好一系列进程，构成一个进程池，然后通过调度器来进行调度，每个工作者负责专门的一些任务，这样一来进程之间可以**共享查询的信息**。

  ![image-20240417165332605](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202404171653752.png)

* 每个工作者对应一个线程。数据库系统只有一个进程，但是一个进程里面有多个工作者线程，这种模型使得数据库系统**可以完全掌握每一个工作者**，并且自己进行线程之间的调度和管理。一个线程crash，整个进程crash。使用这种方式并不意味着这个DBMS支持intra-query parallelism（SQL语句内部并发）。可能一条SQL语句一个线程。

  ![image-20240417165435615](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202404171654726.png)

Inter-Query：不同sql语句并行执行。（后面讲）

Intra-Query：一条sql语句内部并行执行。

#### Intra-Query

对单个查询进行并行化的处理其实就是将查询看成了一个**生产者消费者的模型**，每一个操作符都是一个数据的生产者同时又是下一级的操作符产生的数据的消费者。

怎么切割成子任务分配给不同的线程？下面介绍三种方法。

* Intra-Operator(HorizonTal) 操作符内并行化：将操作符分解成若干独立的片段，这些片段在不同的数据上执行同一个操作。数据库在查询计划中插入一个新的操作符exchange，这个操作符可以阻止位于这个操作符之上的操作符继续执行，直到exchange操作符接收到了下面并行操作的结果。并且exchange操作符也可以分成三种不同的形式：

  - Gather：将多个工作者的结果组合到一个输出流中，最常见的操作符
  - Repartition：重新将多个输入流组织称多个输出流，即输入到输出的重分发。
  - Distribute：将一个输入流分成多个输出流

  ![image-20240417171315255](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202404171713637.png)

  <img src="https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202404171713010.png" alt="image-20240417171335096"  />

* Inter-Operator (Vertical) 操作符间并行化：也称为pipeline parallelism。就是不经过物化(Materialization)直接通过管道pipeline进行数据的处理。

  ![image-20240417171639834](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202404171716091.png)

* Bushy Parallelism 混合并行化：上面两者的混合。

  ![image-20240417171730212](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202404171717715.png)

上面的并行化都是基于CPU的性能是数据库系统的瓶颈，但是如果系统的瓶颈在存储设备，上面的优化就显得没什么用。那么怎么对I/O操作进行并行化处理呢？

#### I/O Parallelism

- 多磁盘的并行化：在多个存储设备上存储数据。

  RAID Configuration（磁盘阵列）（对数据库透明，在DBMS看来，只有一个磁盘，实际上有多个磁盘）

  ![image-20240417172208372](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202404171722049.png)

  ![image-20240417172238035](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202404171722936.png)

- 数据库的分区：将数据库分割成多个逻辑分区，每个逻辑分区之间互不相交并且负责不同的查询处理

  * 垂直分区：将表按照属性存储在不同的区域，并存储元组的结构信息用来重建表

    ![image-20240417172328187](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202404171723140.png)

  * 水平分区：将表的元组分割成不同的段并进行存储

    ![image-20240417172349687](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202404171723579.png)

## 查询优化

![image-20240417183307421](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202404171833697.png)

* 逻辑计划：给sql程序员用的，比如Join
* 物理计划：选择具体的执行方式，比如Merge-Join / Hash Join / Nested Loop Join?

查询优化有两种方式：

* Heuristics / Rules：（启发式/规则式）利用特定的规则对查询进行优化，移走查询中低效率的部分，这些规则可能需要通过catalog来了解数据库中数据存储的结构，但是不需要对数据本身进行检验
* Cost-based Search：（基于代价）将数据读出，并估计出执行不同的等效查询计划的cost，然后选择cost最低的方案执行

### Heuristics / Rules

#### 关系代数等价性

<img src="https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202404171839232.png" alt="image-20240417183926364" style="zoom: 67%;" />

<img src="https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202404171840528.png" alt="image-20240417184001967" style="zoom:67%;" />

#### 逻辑查询优化

**对谓词的优化：**

- 尽早处理filter的操作(这个过程就叫做predicate pushdown)
- 重新对谓词进行排序，让数据库系统首先处理最具选择性的谓词
- 将一个复杂的谓词拆成多个并且下放

<img src="https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202405131822518.png" alt="image-20240417184843005" style="zoom: 67%;" />

<img src="https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202404171849900.png" alt="image-20240417184922074" style="zoom:67%;" />



Inner Join符合交换律和结合律。n表Join有4的n次方种执行方式。是一个Catalan Number。**对Join的优化：**

- 尽早进行投影操作来缩小操作数据的范围

- 只留下查询需要的，其他的都project out

  <img src="https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202404171846279.png" alt="image-20240417184639867" style="zoom:50%;" />



#### 嵌套查询优化

提前执行嵌套查询，并将结果存储在临时的表。

<img src="https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202404171852135.png" alt="image-20240417185239293" style="zoom:67%;" />

如果是火山模型，对于上图的嵌套查询，查询结果为整数，可以提前计算存在临时的表中。

#### 表达式重写

删除查询条件中不必要的谓词或者对不可能的查询条件进行修改。对一些有重复的谓词进行合并。

![image-20240417185351224](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202404171853493.png)

![image-20240417185416347](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202404171854705.png)

### Cost-based Search

cost model components:

* Physical Costs: CPU cycles, I/O, cache misses, RAM consumption
* Logical Costs: 针对每个算子计算它们的开销
* Algorithmic Costs: 算子具体实现算法的开销

在数据库系统中**维护一些关于表/属性/索引的统计信息**，比如有多少元组，每个属性有多少个不同的值等等，这样一来就可以快速找到代价估计时候要用的**关键数据**，避免了边查边用，提高代价估计时候的效率。在不同数据库更新统计信息的命令：

* Postgres/SQLite: ANALYZE
* Oracle/MySQL: ANALYZE TABLE
* SQL Server: UPDATE STATISTICS
* DB2: RUNSTATS

都有哪些统计信息呢？

![image-20240417191415120](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202404171914270.png)

<img src="https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202404171917875.png" alt="image-20240417191743725" style="zoom:80%;" />

在代价估计时，一般要用到以下假设：

- **数据均匀分布**：即大量数据在每个属性上取得每个值的概率是等价的
- **独立性**：每个属性之间是独立的，互相不影响
- **包容原则**：主要是关于join操作的key的，内表中的key都在外表中存在对应。

selectivity(sel)选择性，跟出现的概率很像！

![image-20240417192352641](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202404171923881.png)

![image-20240417192430311](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202404171924671.png)

在这种情况下，**并集和交集的计算**如下（属性之间相互独立）：

![image-20240417192541676](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202404171925302.png)

![image-20240417192558508](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202404171925622.png)

如何预估Join结果的大小？

![image-20240417193140009](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202404171931137.png)

如果不是均匀分配，可以使用直方图：

![image-20240417193337729](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202404171933613.png)

![image-20240417193454696](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202404171934759.png)

可以用sketches去代替histograms，来提高选择性评估的准确性。

* Count-Min Sketch
* HyperLogLog

或者使用抽样的方法，但是要**维护**样本小表还有遍历样本小表需要**开销**。

![image-20240417195634780](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202404171956181.png)

现在我们可以粗略地估计谓词的选择性，以及查询计划的cost，接下来对查询进行优化，分为几种情况：

* 单表查询：顺序查询/二分查询/索引查询，只用Heuristics就够了，不需要用到Cost-based Search。因为它非常简单。也不需要Join。常用于OLTP。

* 多表查询：使用left-deep join

  ![image-20240417200424854](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202404172004862.png)

  实现一种流式的处理，不需要暂存中间结果。

  但是还是需要考虑很多情况：join的顺序？join的算法?(Hash?merge?Nested Loop?) 访问方法？(index? Sequential?)

  使用**动态规划**！

  ![image-20240417200910051](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202404172009929.png)

  使用遗传查询优化器(Genetic Query Optimizer)：不一定能选出最好的，但能选出相对好的。

  ![image-20240417201135511](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202404172011586.png)

## 并发控制理论

**事务**：一个事务是一段连续的执行操作，比如一堆SQL语句，一条SQL语句也能是一个事务。

**strawman system**：

- 事务之间是串行的，事务们一个个的被执行，彼此之间毫无关系
- 当事务开始时，DBMS**复制整个数据库文件**，并对这个新文件进行事务更改。如果事务成功，则新文件将成为当前数据库文件。如果事务失败，DBMS将丢弃新文件，并且未保存任何事务更改。

**数据库只知道执行事务，不知道事务所表达的含义**，在设计并发控制方法之前，我们要对事务有一个良好的抽象。因为数据库只关心对数据做哪些读和写的操作，因此对DBMS来说，**事务就是一段连续的读和写操作**

一个事务开始的标识是 `BEGIN` 指令。

利用 `COMMIT` 或者 `ABORT` 指令停止事务：

- 如果是 `COMMIT` ，DBMS知道这一段操作执行完成了，如果没冲突，则将更改的数据写入，如果冲突，则放弃这些更改的数据。（持久化保存）
- 如果是 `ABORT` ，DBMS知道这表示自主引发的事务中断，所有的更改会被放弃，仿佛事务没发生过。（回滚）

DBMS并发性设计的好不好，有一个**ACID**标准：

- 原子性：事务中的所有操作都会发生，或者不发生
- 一致性：事务的一致性指的是事务必须在执行前后**满足数据库的所有约束**。
- 隔离性：一个事务的执行与其他事务的执行相隔离，一个事务感觉自己独占整个数据库。
- 持久性：如果事务提交，其更改的内容能够被持久化

### Atomicity

两种方式实现原子性：

* **Logging**：Maintain **undo records** both in memory and on disk. DBMS在内存和磁盘上维护当前执行的事务的所有操作。出于便于**审计和高效率**的原因，几乎所有现代数据库系统都使用日志记录。
* **Shadow Paging**：将要被修改的页复制一份，只有当事务提交时，这些page才被写回。但是维护开销大。

### Consistency

有点抽象：划分成**业务一致性**（应用层）和**事务一致性**（DBMS）来理解。

事务的一致性指的是事务必须在执行前后满足数据库的所有约束。

在数据库的角度来看，它只关心 transaction 符不符合定义好的规则，符合的就是legal的，不符合的就是illegal的。

数据库并不知道你应用层的逻辑意义，它不保证应用层的transaction的正确性，这个**逻辑正确性是由应用层的programmer来保证**的。

作者：sleep deep
链接：https://www.zhihu.com/question/31346392/answer/569142076
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。



那么看下面我们熟知的转账的例子。

```text
Table： Account
Columns:   Name(string), Balance（int)
约束条件：无

执行下面一个事务(A,B的初始余额均为1000，A给B转账1200）

1.  往表Account插入数据（A,1000)
2. 往表Account插入数据 （B,1000)
3. A给B转账1200，更新A的余额为-200，（A,-200)
4. B的余额增加1200，更新B的余额为2200（B,2200)
```

那么，数据库会认为这个 transaction 合不合法呢？也就是它满不满足我们给数据库的定义的规则呢？答案就是这个 transaction 是合法的，因为你定义表的时候没有约定 Balance 不能小于0。虽然我们从应用层的角度来看，这个[transaction](https://www.zhihu.com/search?q=transaction&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A569142076})是不正确的，因为它不符合逻辑- balance不能小于0.  但我们数据库只关心你的 transaction 满不满足你的数据库定义的rule，不关心它具有什么业务的逻辑，这个业务逻辑是应该由应用层来理解并处理的。

修改一下上面这个例子

```text
Table： Account
Columns:   Name(string), Balance（int)
约束条件：Balance >= 0

执行下面一个事务(A,B的初始余额均为1000，A给B转账1200）

1.  往表Account插入数据（A,1000)
2. 往表Account插入数据 （B,1000)
3. A给B转账1200，更新A的余额为-200，（A,-200)
4. B的余额增加1200，更新B的余额为2200（B,2200)
```

注意，这里增加了约束条件Balance > 0, 上面的这个transaction违反了规则Balance>=0，那么这个[事务数据库](https://www.zhihu.com/search?q=事务数据库&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A569142076})认为它是非法的，不满足一致性的要求，所以数据库执行这个事务会失败。

### Isolation

DBMS提供了事务在系统中单独运行的假象。

用户提交 transactions，不同 transactions 执行过程应当互相隔离，互不影响，每个 transaction 都认为只有自己在执行。

concurrency control protocol（并发控制协议）：DBMS 如何认定多个 transactions 的重叠执行方式是正确的。

主要有两种protocols：

* **悲观**：假设我们的事务在执行时会产生冲突，导致问题的出现
* **乐观**：假设冲突很少发生，在冲突发生后再处理

如何判断一种重叠的 schdule 是正确的？

**如果某个schedule的执行结果等同于按顺序执行的结果，那么我们就会说这种执行顺序的sechedule是正确的。**

* Serial Schedule：串行执行，不同 transactions 之间没有重叠
* Equivalent Schedules：若两个 schedules 分别执行所到达的数据库最终状态相同，则称这两个 schedules 等价
* Serializable Schedule：这个schedule可以与Serial Schedule执行结果一样，就称之为可串行化的。

#### Conflicting Operations

当两个 operations 满足以下条件时，我们认为它们是 conflicting operations：

- 来自不同的 transactions
- 对同一个对象操作
- 两个 operations 至少有一个是 write 操作

可以穷举出这几种情况：

- Read-Write Conflicts (R-W)
- Write-Read Conflicts (W-R)
- Write-Write Conflicts (W-W)

**Read-Write Conflicts/Unrepeatable Reads（不可重复读）**

<img src="https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202404301827843.png" alt="image-20240430182740846" style="zoom:67%;" />



一个事务先后读取同一条记录，但两次读取的数据不同。

**Write-Read Conficts/Reading Uncommitted Data/Dirty Reads （脏读）**

<img src="https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202404301830150.png" alt="image-20240430183030867" style="zoom:67%;" />

一个事务读到另一个事务没有提交的数据

**Write-Write Conflicts/Overwriting Uncommitted Data**

<img src="https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202404301831611.png" alt="image-20240430183119121" style="zoom:67%;" />

**serializability 对一个 schedule 意味着这个 schedule 是否正确**。

serializability 有两个不同的级别：

Conflict Serializability (Most DBMSs try to support this) 基于冲突的可串行化：

- 如果通过交换不同 transactions 中连续的 non-conflicting operations 可以将 S 转化成 serial schedule，则称 S 是 conflict serializable
- 反着讲，先把conflicting operations找到，这些就是不可交换的，看看这些conflicting operations固定住，能否形成serial schedule

View Serializability (No DBMS can do this) 基于观察的可串行化

#### Conflict Serializability

例 1：将 conflict serializable schedule S 转化为 serial schedule

<img src="https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202404301843750.png" alt="image-20240430184334712" style="zoom: 67%;" />

<img src="https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202404301844890.png" alt="image-20240430184423662" style="zoom:67%;" />

<img src="https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202404301844771.png" alt="image-20240430184444828" style="zoom:67%;" />

<img src="https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202404301845764.png" alt="image-20240430184503630" style="zoom:67%;" />

![image-20240430184528893](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202404301845478.png)

例2：S不能成为serial schedule

<img src="https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202404301846473.png" alt="image-20240430184629495" style="zoom:67%;" />

有没有什么更快的算法来判断一个schedule是否是serializable的？

**Dependency Graphs 依赖图**

每个事务一个结点，依赖图无循环，那么它就是conflict serializable 的。

![image-20240430192500992](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202404301925989.png)

![image-20240430192515915](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202404301925908.png)

成环了，不是可串行化的。

下面举一个可串行化的例子：

![image-20240430192647333](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202404301926392.png)

#### View Serializability

上面这种判断可串行化的方式可能会有问题，例如：

![image-20240430192948201](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202404301929145.png)

在这个例子中，它是不可串行化的。

* 事务T1就是A给B转了10块钱，在上图中，就是求转完钱（或者转钱之前，都一样）A和B的钱的和，假设serial schedule: T1 -> T2，仔细思考，上图`schedule`求出来的`sum` 和 `serial schedule` 求出来的 `sum`不一样，不可串行化

但是

<img src="https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202404301930821.png" alt="image-20240430193025813" style="zoom:67%;" />

* 这里，求的是，转完钱A和B的值是否依然大于0，假设serial schedule: T1 -> T2，上图的结果与serial schedule的结果是一样的（B >= 0  ->  B + 10 >= 0）

  按理来说，上面这种schedule是可串行化的。基于冲突的可串行化判断就出错了。

View Serializable 就是一种基于逻辑判断的，计算机很难实现，所以几乎没有DBMS使用。

![image-20240430195021725](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202404301950688.png)

### Durability

所有已提交事务的更改都应该是持久的。

## 二阶段锁

为什么要引入二阶段锁？

上面讲的基于冲突的可串行化判断前提是**预先知道所有事务的执行流程**，这与真实的数据库使用场景并不符合。因此我们需要一种方式来保证数据库最终使用的 schedule 是正确的 (serializable)。不难想到，保证 schedule 正确性的方法就是合理的加锁 (locks) 策略，2PL 就是其中之一。

![image-20240430195342753](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202404301953510.png)

![image-20240430195419898](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202404301954918.png)

* DBMS 中有个专门的模块`lock manager`，负责管理系统中的 locks，每当事务需要加锁或者升级锁的时候，都需要向它发出请求
* lock manager 内部维护着一个 lock table，上面记录着当前的所有分配信息，lock manager 需要根据这些来决定赋予锁还是拒绝请求

![image-20240430195649429](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202404301956630.png)

2PL，顾名思义，有两个阶段：growing 和 shrinking

在 growing 阶段中，事务可以按需获取某条数据的锁，lock manager 决定同意或者拒绝；在 shrinking 阶段中，事务只能释放之前获取的锁，不能获得新锁，即一旦开始释放锁，之后就只能释放锁。

![image-20240430200004297](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202404302000239.png)

![image-20240430200021533](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202404302000391.png)

2PL会面临两个问题，一个是级联中止，一个是死锁

### 级联中止

![image-20240501134212557](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202405011342716.png)

级联中止 (cascading aborts)：T2脏读，DBMS 需要在 T1 中止后将**曾经读取过** T1 写入数据的其它事务中止，而这些中止可能进而使得其它正在进行的事务级联地中止。

**Strong Strict 2PL (aka Rigorous 2PL)**

增强版2PL。在事务最后commit或者abort的时候才释放所有锁。

![image-20240501134503599](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202405011345890.png)

可以避免级联中止，而且回滚操作简单。

下面我们以转账为例，对 Non-2PL、2PL 和 Rigorous 2PL 分别举例：

- T1：从 A 向 B 转账 100 美元
- T2：计算并输出 A、B 账户的总和

Non-2PL 举例：T2读取T1写到一半的数据，结果不正确。

![image-20240501134654887](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202405011346214.png)

2PL举例：是正确的。

![image-20240501135014490](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202405011350810.png)

SS2PL举例：

![image-20240501135101484](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202405011351773.png)

### 死锁

死锁：事务之间互相等待对方释放自己想要的锁。

#### Detection

死锁检测是一种事后行为。

为了检测死锁，DBMS 会维护一张 waits-for graph，waits-for graph 中的节点是事务，从 𝑇𝑖 到 𝑇𝑗 的边就表示 𝑇𝑖 正在等待 𝑇𝑗 释放锁。然后系统会定期地检查 waits-for graph，看其中是否有成环，如果成环了就要**决定**如何打破这个环。

![image-20240501135441774](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202405011354705.png)

当 DBMS 检测到死锁时，它会选择一个 "受害者" (事务)，将该事务回滚，打破环形依赖。这里有两个设计决定：

- **检测死锁的频率**：检测死锁的频率越高，陷入死锁的事务等待的时间越短，但消耗的 cpu 也就越多。所以这是个典型的 trade-off，通常有一个调优的参数供用户配置。
- **如何选择合适的 "受害者"**：事务持续时间、事务的进度、事务锁住的数据数量、级联事务的数量、事务曾经重启的次数等等。在选择完 "受害者" 后，DBMS 还有一个设计决定需要做：**完全回滚**还是**回滚到足够消除环形依赖**（部分回滚）即可。

#### Prevention

死锁预防是一种事前行为。

通常 prevention 会按照事务的年龄来赋予优先级，**事务的时间戳越老，优先级越高。**有两种 prevention 的策略：

- Wait-Die("Old Waits for Young")：如果 requesting txn 优先级比 holding txn 更高则等待后者释放锁；更低则自行中止（老的等年轻的，反之，年轻自杀）
- Wound-Wait("Young Waits for Old")：如果 requesting txn 优先级比 holding txn 更高则后者自行中止释放锁，让前者获取锁，否则 requesting txn 等待 holding txn 释放锁（年轻的等老的，反之，老的抢年轻的）

![image-20240501140510923](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202405011405215.png)

其原理类似哲学家就餐设定顺序的解决方案：先给哲学家排个序，遇到获取刀叉冲突时，顺序高的优先。被中止的事务，重启时的时间戳是旧的时间戳。

### Hierarchical Locking

上面的例子中所有的锁都是针对单条数据 (database object)，如果一个事务需要更新十亿条数据，那么 lock manager 中的 lock table 就要撑爆了。因此需要有一些手段能够将锁组织成树状/层级结构，减少一个事务运行过程中需要记录的锁的数量。

上锁的粒度不同。

![image-20240501140811860](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202405011408044.png)

如果Tuple n上了一个X锁，那么Table 1就不能上X锁，但是我怎么知道Table 1不能上X锁呢？要遍历所有Tuple检查看看是否上X锁嘛？开销就会很大。所以我们可以考虑在Table加上一个标记，记录自己有子节点在上X锁。这里引入意向锁的概念。

**Intention Locks（意向锁）**：意向锁允许将更高级别的节点锁定为共享或独占模式，而无需检查所有后代节点。

* Intention-Shared (IS)：有子节点上了S锁
* Intention-Exclusive (IX)：有子节点上了X锁
* Shared+Intention-Exclusive (SIX)：有子节点上了X锁，并且自己上了S锁

![image-20240501141443466](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202405011414607.png)

举个例子：

![image-20240501141701342](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202405011417792.png)

![image-20240501141901710](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202405011419718.png)

![image-20240501141949683](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202405011419606.png)

![image-20240501142101553](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202405011421504.png)

## Timestamp Ordering Concurrency Control

上节课介绍的 2PL 是**悲观的**并发控制策略，本节课介绍的 Timestamp Ordering (T/O) 则是一个乐观的策略，其乐观表现在事务访问数据时无需显式加锁。

### Basic T/O

在 Basic T/O 中，事务读写数据不需要加锁，每条数据 X 都会携带两个标记：

- W-TS(X)：最后一次写 X 发生的时间戳
- R-TS(X)：最后一次读 X 发生的时间戳

在每个事务结束时，Basic T/O 需要检查该事务中的每个操作，是否读取或写入了**未来的数据**，一旦发现则中止、重启事务。

#### Basic T/O Reads

如果事务 𝑇𝑖发生在 W-TS(X) 之前，即尝试读取未来的数据，则中止 𝑇𝑖 

![image-20240513210548613](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202405141110573.png)

#### Basic T/O Writes

如果事务 𝑇𝑖 发生在 W-TS(X) 或 R-TS(X) 之前，即尝试写入已经被未来的事务读取或写入的数据，则中止 𝑇𝑖 

![image-20240513210722089](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202405141110655.png)

举例：

![image-20240513211334746](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202405141110520.png)

![image-20240513211437009](C:/Users/z1382/AppData/Roaming/Typora/typora-user-images/image-20240513211437009.png)

下面这种情况就是不可以的

![image-20240513211517807](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202405141110149.png)

**Thomas Write Rule (TWR)**

你会发现上面这个例子，T1在T2之前发生，就是说T2会将T1写的A覆盖。

如果我们忽略掉 𝑇1的 W(A) 操作，即不更新 A 数据，也不修改 W-TS(A)，那么 𝑇1 和 𝑇2 都可以正常提交，且结果和二者先后执行等价

TWR 优化了 Basic T/O 的写检查，使得一些本不必中止的事务顺利进行，提高了事务并发程度。

Basic T/O 的**优势**在于：

- 不会造成死锁（因为根本没有锁），因为没有事务需要等待
- 如果单个事务涉及的**数据不多**、不同事务涉及的数据基本不相同 (OLTP)，可以节省 2PL 中控制锁的额外成本，提高事务并发度

其缺点在于：

- 长事务容易因为与短事务冲突而饿死
- 复制数据，维护、更新时间戳存在额外成本
- 可能产生不可恢复的 schedule (具体见下图)

![image-20240513212434838](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202405141110801.png)

### Optimistic Concurrency Control(OCC)

在 OCC 中，数据库为每个事务都创建一个私有空间：

- 所有**被读取**的数据都复制到私有空间中
- 所有修改都在私有空间中执行

OCC 分为 3 个阶段：

- Read Phase：追踪、记录每个事务的读、写集合，并存储到私有空间中
- Validation Phase：当事务提交时，检查冲突
- Write Phase：如果校验成功，则合并数据；否则中止并重启事务

![image-20240513212929904](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202405141110016.png)

事务 𝑇2完成数据操作，在 Validation Phase 中获得事务时间戳 1，由于没有数据写入，跳过 Write Phase

![image-20240513213018795](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202405141110085.png)

事务 𝑇1在 Validation Phase 获得事务时间戳 2，并通过校验，将 W-TS(A) 修改为 2，并合并到数据库中

#### Read Phase

将 read set 存放在 private workspace 中用来保证 repeatable read，将 write set 存放在 private workspace 中用来作冲突检测。

#### Validation Phase

在进入 Validation Phase 后，每个事务都会被赋予一个时间戳，然后与其它正在运行的事务执行 Timestamp Ordering 检查，检查的方式有两种：

- Backward Validation（历史）

  需要检查待提交的事务 (txn #2) 的读写集合是否与已经提交的事务的读写集合存在交集

  ![image-20240513213239856](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202405141110113.png)

- Forward Validation（未来）

  需要检查待提交的事务 (txn #2) 的读写集合是否与尚未提交的事务的读写集合存在交集

  ![image-20240513213253177](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202405141110890.png)

下面这些都是Forward Validation，就是向未来的事务校验

如果TS(Ti) < TS(Tj)，以下3个条件之一必须成立：

* 完全就是串行化执行

  <img src="https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202405141110233.png" alt="image-20240513213519504" style="zoom:50%;" />

* 如果T1的时间戳比T2小，就说明我要比你先发生，那么你只能在我修改的基础上读取数据

  我修改的数据Write

  WriteSet(Ti) ∩ ReadSet(Tj) = Ø

  ![image-20240513213834388](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202405141111024.png)

  这种情况下会发生错误：

  * T1先进入Validate，T1的时间戳是1，T1要比T2先发生
  * 那么T2读取的应该是，T1 write phase之后的数据
  * 但是上图中，T2读取的是T1还未提交的数据

  修改成下面这种情况就正确了。

  ![image-20240513214249386](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202405141111434.png)

* ![image-20240513214729447](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202405141111459.png)

  ![image-20240513214746472](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202405141111350.png)

  这是可行的，其实跟上面那个例子很像。

#### Write Phase

直接锁全表，进行写回。不并发。

#### Summary

当冲突发生的频率很低时，即：

- 大部分事务都是读事务
- 大部分事务之间访问的数据间没有交集

OCC 的表现很好，如在数据库体量较大，workload 比较均衡的场景下。

2PC 的性能瓶颈在于锁管理，尽管 OCC 没有加锁的成本，但它也存在性能问题:

- 在 private workspace 与 global database 之间移动、合并数据开销大
- Validation（判断冲突的过程很复杂）/Write Phase（无法并发） 需要在一个全局的 critical section 中完成，可能造成瓶颈
- 事务中止的成本比 2PL 高（都做完了，然后开始判断冲突，有冲突，再重做）

### Isolation Level

到现在为止，我们都只考虑事务读取和更新数据，如果我们再考虑插入、删除操作，就会遇到新的问题。

**The Phantom Problem 幻读问题**

即在单个事务内部，同样的查询，读到不一样的数据。

![image-20240514111607800](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202405141116605.png)

尽管 𝑇1 锁住了已经存在的记录，但新生成的记录并不会被锁住，因此实际上 **conflict serializability 能保证事务可序列化的前提是数据集合是固定的**，出现记录新增和删除时，这个结论就不成立了。

有以下几种解决办法：

* **Re-Execute Scans**：比较暴力的做法是在事务提交时，扫描 `status = 'lit'` 的所有数据，检查这些数据是否与事务操作之前的数据相同。目前没有任何商业数据库采用这种方案。

* **predicate locking**：谓词锁，如：`status = 'lit'` ，给这么一条谓词上锁。然而，predicate locking 的成本很高，对每条新插入的数据都需要做校验。基本没有 DBMS 用这种方式实现，一种更高效的做法是 index locking。

  ![image-20240514112323618](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202405141123826.png)

* **Index Locking**：如果在 `status` 字段上有索引，那么我们可以锁住满足 `status = 'lit'` 的 index page

* **Locking Without An Index**：

* 如果在 `status` 字段上没有索引，那么事务就需要执行以下操作：

  - 获取 table 的每个 page 上的锁，防止其它记录的 `status` 被修改成 `lit`
  - 获取 table 本身的锁，防止满足 `status = 'lit'` 的记录被插入或删除

可序列化的方案要求比较严格，会对系统的并发度和性能造成较大的限制，因此我们也许能够用更弱的数据一致性保证去改善系统的扩展性。这也是所谓的数据库隔离级别。

* READ UNCOMMITTED：该隔离级别的事务可以看到其他事务中未提交的数据。该隔离级别因为可以读取到其他事务中未提交的数据，而未提交的数据可能会发生回滚，因此我们把该级别读取到的数据称之为脏数据，把这个问题称之为脏读。
* READ COMMITTED：该隔离级别的事务能读取到已经提交事务的数据，因此它不会有脏读问题。但由于在事务的执行中可以读取到其他事务提交的结果，所以在不同时间的相同 SQL 查询中，可能会得到不同的结果，这种现象叫做不可重复读。
* REPEATABLE READS：所谓的幻读指的是，在同一事务的不同时间使用相同 SQL 查询时，会产生不同的结果。例如，一个 SELECT 被执行了两次，但是第二次返回了第一次没有返回的一行，那么这一行就是一个“幻像”行。

**幻读和不可重复读的侧重点是不同的**，不可重复读侧重于数据修改，两次读取到的同一行数据不一样；而幻读侧重于添加或删除，两次查询返回的数据**行数不同**。

这里关于幻读又有另外一种理解。

![image-20240615193134443](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202406151931657.png)

最终 事务A 提交事务，发现报错了。这就很奇怪，查的时候明明没有这条记录，但插入的时候 却告诉我 主键冲突，这就好像幻觉一样。这才是所有的幻读。

**不可重复读侧重表达 读-读，幻读则是说 读-写，用写来证实读的是鬼影**。

* SERIALIZABLE：序列化，事务最高隔离级别，它会强制事务排序，使之不会发生冲突，从而解决了脏读、不可重复读和幻读问题，但因为执行效率低，所以真正使用的场景并不多。

![image-20240514112853543](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202405141128816.png)

![image-20240514112718884](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202405141127832.png)

## Multi-Version Concurrency Control



MVCC 并不只是一个并发控制协议，并发控制协议只是它的一个组成部分。它深刻地影响了 DBMS 管理事务和数据的方式，使用 MVCC 的 DBMS 数不胜数。

**Concurrency Control Protocol**

* Timestamp Ordering (T/O)
* Optimistic Concurrency Control (OCC)
* Two-Phase Locking (2PL)

**Version Storage**

DBMS 通常会在每条数据上拉一条版本链表 (version chain)，所有相关的索引都会指到这个链表的 head，DBMS 可以利用它找到一个事务应该访问到的版本。

* Append-Only Storage：新版本通过追加的方式存储在同一张表中
* Time-Travel Storage：老版本被复制到单独的一张表中
* Delta Storage：老版本数据的被修改的字段值被复制到一张单独的增量表 (delta record space) 中

![image-20240518170143495](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202405181701525.png)

### MVTO

首先，MVCC方法不允许读未提交的tuple，也就是说，一个tuple的写锁被持有，就不允许其他事务读写。

下面是MVTO一个tuple的架构

```
| header |  column |
     |
     ↓
| txn-id | read-ts | begin-ts | end-ts|
txn-id就是说当前tuple被谁持有，持有的事务id是多少，
begin-ts和end-ts描述一个tuple的生命周期，当tuple被删除
read-ts是代表谁目前在读这个tuple
```

* 对于读操作：
  * 当前事务Tid要位于[begin-ts, end-ts)之中
  * 确定写锁是否被占有(**txn-id是否为0或者为自己Tid**，因为MVTO不允许读未commit的数据)
* 对于写操作：
  * 当前事务Tid要位于[begin-ts, end-ts)之中
  * 确定写锁是否被占有(txn-id是否为0或者为自己Tid，因为MVTO不允许读未commit的数据)
  * Tid要大于Bx的read-ts

举个例子：

```
   | txn-id | read-ts | begin-ts | end-ts |
Ax | 0      |    0    | 10       | 20     |
Bx | 0      |    17   | 15       | 30     |
```

事务T要更新tuple Bx，假设Tid = 18， 发现条件允许，新增版本

```
     | txn-id | read-ts | begin-ts | end-ts |
Ax   | 0      |    0    | 10       | 20     |
Bx   | Tid    |    17   | 15       | 30     |
Bx+1 | Tid    |    0    | --       | --     |   //新版本的事务还在执行
```

--其实是INF，就是无穷大

commit之后

```
     | txn-id | read-ts | begin-ts | end-ts |
Ax   | 0      |    0    | 10       | 20     |
Bx   | 0      |    17   | 15       | 30     |
Bx+1 | 0      |    18   | 18       | --     |   
```



## 日志

### 故障分类

* 事务故障（出现频率高，不可避免，设计数据库要考虑）
  * 逻辑错误 (Logical Errors)：由于一些**内部约束**，如数据一致性约束，导致事务无法正常完成
  * 内部错误 (Internal State Errors)：由于数据库**内部调度**、并发控制，如**死锁**，导致事务无法正常提交
* 系统故障（设计数据库也要考虑）
  * 软件故障 (Software Failure)：如 DBMS 本身的实现问题 (NPE, Divide-by-zero)
  * 硬件故障 (Hardware Failure)：DBMS 所在的宿主机发生崩溃，如**断电**。且一般假设非易失性的存储数据在宿主机崩溃后不会丢失
* 存储介质故障（设计数据库时不用考虑）
  * 通常这样的故障就是**无法修复**的，如发生撞击导致磁盘部分或全部受损。所有数据库都无法从这种故障中恢复，这时候数据库只能从归档的备份记录中恢复数据。

### 缓存池策略

DBMS 需要保证两点：

- DBMS 告知用户事务已经提交成功前，相应的数据必须已经持久化
- 如果事务中止，任何数据修改都不应该持久化

DBMS 有两种基本思路来恢复数据一致性，向用户提供上述两方面保证：

- Undo：将中止或**未完成**的事务中已经执行的操作回退
- Redo：将**提交**的事务执行的操作重做

Steal和Force：

* Steal：可以将未提交事务所做的修改落到硬盘。
* No-Steal：任何未提交事务所做的修改都无法落地到磁盘
* Force：一commit，就刷脏
* No-Force：commit的时候不刷脏

**在实践中使用的主要是 No-Steal + Force 和 Steal + No-Force。**

举个例子：

![image-20240528185810873](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202405281858642.png)

* 事务中止后，无需回滚数据，因为该事务修改的数据不会被别的事务捎带落盘
* 事务提交后，无需重做数据，因为该事务修改的数据必然会被落盘持久化

### Shadow Paging

shadow paging 是 No-Steal + Force 策略的典型代表，它会维护两份数据库数据：

- Master：包含所有已经提交事务的数据
- Shadow：在 Master 之上增加未提交事务的数据变动

![image-20240528190304282](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202405281903798.png)

![image-20240528190421675](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202405281904223.png)

![image-20240528190525877](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202405281905956.png)

**优点**：

* **实现简单**
* **恢复数据很容易**：
  * Undo/Rollback：删除 shadow pages (table)，啥都不用做
  * Redo：不需要 redo，因为每次写事务都会将数据落盘

**缺点**：

* **复制整个 page table 代价较大**
* **事务提交的代价较大**，在事务提交时，要干下面这么多事情：
  * 将数据落盘
  * 做垃圾清理
  * 容易产生磁盘碎片，使得原先距离近的数据渐行渐远
  * 只支持一个写事务或一批写事务一次性持久化

### Write-Ahead Log

WAL 指的是 DBMS 除了维持正常的数据文件外，额外地维护一个日志文件，上面记录着所有事务对 DBMS 数据的完整修改记录，这些记录能够帮助数据库在恢复数据时执行 undo/redo。

*WAL Protocol*

1. DBMS 先将事务的操作记录放在内存中 (backed by buffer pool)
2. 在将 data page 落盘前，所有的日志记录必须先落盘
3. 在操作日志落盘后，事务就被认为已经提交成功

事务开始时，需要写入一条 `<BEGIN>` 记录到日志中；事务结束时，需要写入一条 `<COMMIT>` 记录到日志中；在事务执行过程中，每条日志记录着数据修改的完整信息，如：

- Transaction Id (事务 id)
- Object Id (数据记录 id)
- Before Value (修改前的值)，用于 undo 操作
- After Value (修改后的值)，用于 redo 操作

每次事务提交时，DBMS 都必须将日志记录落盘，由于落盘的操纵对于内存操作来说用时较长，因此可以利用 group commit 来批量刷盘从而均摊落盘成本

![image-20240528192259648](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202405281923110.png)

日志的格式：

* physical logging：记录物理数据的变化。但是如果一条SQL语句修改非常多数据，那么这个日志就会非常大。
* logical logging：记录逻辑操作内容，如 UPDATE、DELETE 和 INSERT 语句等。如果有now函数，在redo的时候，时间就不一样了。还有SQL中的limit不保证吐出哪些数据。

* physiological logging：这种方案不会像 physical logging 一样记录 **xx page xx 偏移量**上的数据发生 xx 改动，而是记录 **xx page 上的 id 为 xx 的数据**发生 xx 改动，前者需要关心 data page 在磁盘上的布局，后者则无需关心

![image-20240528192535712](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202405281925792.png)

### Checkpoints

如果我们放任 WAL 增长，它可以随着新的操作执行而无限增长。为了避免这种情况出现，DBMS 需要周期性地记录 checkpoint，即将所有日志记录和数据页都持久化到存储设备中，然后在日志中写入一条 `<CHECKPOINT>` 记录，举例如下：

![image-20240528192832586](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202405281928788.png)

关于checkpoints，下一章有更多的讲解。

## 恢复

### Log Sequence Numbers

WAL 中的每条日志记录都需要包含一个全局唯一的 log sequence number (LSN)，一般 LSN 单调递增。DBMS 中的不同部分都需要记录相关的 LSN 信息。

| name         | where            | Definition                                                   |
| ------------ | ---------------- | ------------------------------------------------------------ |
| flushedLSN   | memory           | 最后落盘的那个 LSN（比如flushedLSN=100，表示前100号日志都已经落盘） |
| pageLSN      | buffer pool page | 与某 page data 相关的最新 LSN                                |
| recLSN       | buffer pool page | 在上次落盘之后，与某 page data 相关的最老 LSN                |
| lastLSN      | transaction      | 某事务最后一条日志的 LSN                                     |
| MasterRecord | disk             | 最近一次 checkpoint 的 LSN                                   |

![image-20240528194608418](C:/Users/z1382/AppData/Roaming/Typora/typora-user-images/image-20240528194608418.png)

### Normal Commit

本节我们来看下**不存在故障时，事务的正常执行过程。**在讨论之前，我们需要约定 4 个假设，简化问题：

- 所有日志记录都能放进一个 page 中
- 写一个 page 到磁盘能保持原子性
- 没有 MVCC，使用严格的 2PL
- 使用 WAL 记录操作日志，buffer pool policy 为 Steal + No-Force

正常提交的时候：

* DBMS 先写入一条 COMMIT 记录到 WAL
* 然后将 COMMIT 及之前的日志落盘，当落盘完成后，flushedLSN 被修改为 COMMIT 记录的 LSN，同时 DBMS 将内存中 COMMIT 及其之前的日志清除。
* 当**数据落盘**时，再写入一条 TXN-END 记录到 WAL 中，表示整个事务完成。

### Abort Operations

同一个事务的每条日志中需要记录上一条记录的 LSN，即 prevLSN，一个特殊情况是：第一条 BEGIN 记录的 prevLSN 为空。

![image-20240528200045006](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202405282000542.png)

为了防止在回滚过程中再次故障导致**部分操作被执行多次**，回滚操作也需要写入日志中，等待所有操作回滚完毕后，DBMS 再往 WAL 中写入 TXN-END 记录，意味着所有与这个事务有关的日志都已经写完，不会再出现相关信息。

**Compensation Log Records（CLR）**

![image-20240528200256958](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202405282002005.png)

CLR 记录的是 undo 操作，例如上图，undo操作就是将40变回30.

同时还记录undoNext 指针，指向下一个将要被 undo 的 LSN，CLR 本身也是操作记录，因此它也需要像其它操作一样写进 WAL 中。

**CLR不需要被回滚。**

### Fuzzy Checkpointing

使用 Non-fuzzy 的方式做 checkpoints 时，DBMS 会**暂停所有工作**，保证落盘的是一个 consistent snapshot，整个过程包括：（保证的是一致性，在制作checkpoints时没有更新修改的事务）

- 停止任何新的事务
- 等待所有活跃事务执行完毕
- 将所有脏页落盘

显然这种方案很糟糕。

**Slightly Better Checkpoints**

Non-fuzzy 需要停止所有事务，并且等待所有活跃事务执行完毕。

而这一种方案，在checkpoint时，还在活跃（就是还没有commit的事务）的事务，可以继续执行，并且给自己执行所需要的页上锁。此时 DBMS 只管扫描一遍 buffer pool 中的 pages，将所有脏页落盘。

因此整个 checkpoint 过程需要两类信息：

- 活跃事务表：Active Transaction Table (ATT)
- 脏页表：Dirty Page Table (DPT)

**Fuzzy Checkpoints**

fuzzy checkpoint 允许任何活跃事务在它落盘的过程中执行。既然允许活跃事务执行，checkpoint 在 WAL 中的记录就不是孤零零的一条，而是一个区间，因此我们需要两类记录来标记这个区间：

- CHECKPOINT-BEGIN：checkpoint 的起点
- CHECKPOINT-END：checkpoint 的终点，同时包含 ATT 和 DPT 记录

当 checkpoint 成功完成时，CHECKPOINT-BEGIN 记录的 LSN 才被写入到数据库的 MasterRecord 中，任何在 CHECKPOINT-BEGIN 之后才启动的事务不会被记录在 CHECKPOINT-END 的 ATT 中，

![image-20240528213026350](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202405282130797.png)

### Recovery Algorithm

 **ARIES**

故障恢复算法分为三个阶段：

* 分析：从 WAL 中读取最近一次 checkpoint，找到 buffer pool 中相应的脏页以及故障时的活跃事务
* 重做：从正确的日志点开始重做所有操作，包括将要中止的事务
* 撤销：将故障前未提交的事务的操作撤销

![image-20240528213253572](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202405282132856.png)

**分析阶段**

太抽象了，直接举个例子吧

![image-20240528213825682](https://raw.githubusercontent.com/ZhouYixiuuuu/picture/master/imgs/202405282138296.png)

**重做阶段**

从 DPT 中找到**最小的 recLSN**（这里需要redo或者需要undo的事务我都给你redo一遍，**就算你是abort的事务，我也给你redo**，即重做CLRs），从那里开始重做更新记录和 CLR，除非遇到以下两种情况：

- 受影响的 page 不在 DPT 中**（这个页已经落盘）**
- 受影响的 page 在 DPT 中，但那条记录的 LSN 小于那个 page 的 recLSN**（这个日志对这一页的影响已经flush了）**

以上两点表示page做的修改已经落盘了。

重做时，需要：

- 重新执行日志中的操作
- 将 pageLSN 修改成日志记录的 LSN
- 不再新增操作日志，也不强制刷盘

在 Redo Phase 结束时，会为所有状态为 COMMIT 的事务写入 TXN-END 日志，同时将它们从 ATT 中移除。

**撤销阶段**

将所有 Analysis Phase 判定为 U (candidate for undo) 状态的事务的所有操作按执行顺序倒序撤销，并且为每个 undo 操作写一条 CLR。

问题：

* 在分析阶段或者重做阶段，数据库再一次CRASH，需要做什么额外的操作吗？

  不需要！直接用日志再一次恢复。

* 在redo阶段，有什么可以提升性能的做法吗？

  一边redo，一边提供服务。

* 在undo阶段，有什么可以提升性能的做法吗？

  * 当有事务访问到需要undo的页时，再进行undo
  * 工程师写代码时，不要写长事务。

## 内存数据库

* 假设所有数据都能存在内存
* 磁盘I/O不是最大的开销了

不再创建buffer pool，或者创建指针

HyPer

